{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omnimodkit import ModelsToolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model toolkit\n",
    "modkit = ModelsToolkit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model synchronously\n",
    "modkit.text_model.run(\n",
    "    user_input=\"What is the capital of France?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream responses from the model\n",
    "for response in modkit.text_model.stream(\n",
    "    user_input=\"What is the capital of France?\",\n",
    "):\n",
    "    print(response, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images\n",
    "modkit.image_generation_model.run(\n",
    "    user_input=\"Draw a cat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use audio recognition\n",
    "import io\n",
    "import requests\n",
    "\n",
    "url = \"https://cdn.openai.com/API/examples/data/ZyntriQix.wav\"\n",
    "audio_bytes = io.BytesIO(requests.get(url, timeout=10).content)\n",
    "audio_bytes.name = \"audio.wav\"\n",
    "modkit.audio_recognition_model.run(\n",
    "    in_memory_audio_stream=audio_bytes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use image recognition\n",
    "import io\n",
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Flagro/treefeeder/main/logo.png\"\n",
    "image_bytes = io.BytesIO(requests.get(url, timeout=10).content)\n",
    "image_bytes.name = \"image.png\"\n",
    "modkit.vision_model.run(\n",
    "    in_memory_image_stream=image_bytes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use audio generation\n",
    "modkit.audio_generation_model.run(\n",
    "    user_input=\"Hello! How can I help you today?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OmniModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omnimodkit import OmniModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omni_model = OmniModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image\n",
    "\n",
    "omni_model.run(\n",
    "    user_input=\"Give me an image of a cat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just text\n",
    "\n",
    "omni_model.run(\n",
    "    user_input=\"Tell me a joke\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get audio response\n",
    "\n",
    "omni_model.run(\n",
    "    user_input=\"Tell me a joke with voice\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image and text\n",
    "\n",
    "omni_model.run(\n",
    "    user_input=\"Show me a cat and tell me about it\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream responses\n",
    "\n",
    "for response in omni_model.stream(\n",
    "    user_input=\"Tell me a joke\",\n",
    "):\n",
    "    print(response.text_new_chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async stream responses\n",
    "\n",
    "async for response in omni_model.astream(\n",
    "    user_input=\"Tell me a joke\",\n",
    "):\n",
    "    print(response.text_new_chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async stream responses with image generation\n",
    "\n",
    "last_response = None\n",
    "async for response in omni_model.astream(\n",
    "    user_input=\"Draw a cat and provide some text about it\",\n",
    "):\n",
    "    if response.text_new_chunk:\n",
    "        print(response.text_new_chunk, end=\"|\", flush=True)\n",
    "    last_response = response\n",
    "\n",
    "print(\"\\nFinal response:\", last_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use audio recognition\n",
    "import io\n",
    "import requests\n",
    "\n",
    "url = \"https://cdn.openai.com/API/examples/data/ZyntriQix.wav\"\n",
    "audio_bytes = io.BytesIO(requests.get(url, timeout=10).content)\n",
    "audio_bytes.name = \"audio.wav\"\n",
    "omni_model.run(\n",
    "    user_input=\"Draw an image based on the audio and tell me about it.\",\n",
    "    in_memory_audio_stream=audio_bytes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use image recognition\n",
    "import io\n",
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Flagro/treefeeder/main/logo.png\"\n",
    "image_bytes = io.BytesIO(requests.get(url, timeout=10).content)\n",
    "image_bytes.name = \"image.png\"\n",
    "omni_model.run(\n",
    "    user_input=\"Describe this image and generate a related image.\",\n",
    "    in_memory_image_stream=image_bytes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate price for a model run\n",
    "import io\n",
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Flagro/treefeeder/main/logo.png\"\n",
    "image_bytes = io.BytesIO(requests.get(url, timeout=10).content)\n",
    "image_bytes.name = \"image.png\"\n",
    "omni_model.estimate_price(\n",
    "    user_input=\"What is the capital of France?\", in_memory_image_stream=image_bytes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
