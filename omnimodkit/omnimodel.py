import io
from typing import Optional, Literal
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Dict
from .ai_config import AIConfig
from .models_toolkit import ModelsToolkit


class TextResponse(BaseModel):
    text: str = Field(
        default="",
        description="Text response generated by the model.",
    )


class ImageResponse(BaseModel):
    image_description_to_generate: str = Field(
        default="",
        description="Description of the generated image.",
    )


class AudioResponse(BaseModel):
    audio_description_to_generate: str = Field(
        default="",
        description="Description of the generated audio.",
    )


class TextWithImageResponse(BaseModel):
    text: str = Field(
        default="",
        description="Text response generated by the model.",
    )
    image_description_to_generate: str = Field(
        default="",
        description="Description of the generated image.",
    )


class OmniModelOutputType(BaseModel):
    output_type: Literal["text", "image", "audio", "text_with_image"] = Field(
        default="text",
        description="Type of output expected from the model.",
    )


class OmniModelOutput(BaseModel):
    model_config = ConfigDict(
        arbitrary_types_allowed=True,
    )

    text_response: Optional[str] = Field(
        default=None,
        description="Text response from the model.",
    )
    image_url_response: Optional[str] = Field(
        default=None,
        description="Generated image URL response from the model.",
    )
    audio_bytes_response: Optional[io.BytesIO] = Field(
        default=None,
        description="In-memory audio bytes response from the model.",
    )


class OmniModel:
    def __init__(
        self, openai_api_key: Optional[str] = None, ai_config: Optional[AIConfig] = None
    ):
        self.ai_config = ai_config
        self.modkit = ModelsToolkit(openai_api_key=openai_api_key, ai_config=ai_config)

    def _get_text_response(
        self,
        user_input: Optional[str] = None,
        system_prompt: Optional[str] = None,
        communication_history: Optional[List[Dict[str, str]]] = None,
    ) -> OmniModelOutput:
        text_response = self.modkit.text_model.run(
            system_prompt=system_prompt,
            user_input=user_input,
            communication_history=communication_history,
        )
        return OmniModelOutput(text_response=text_response.text)

    async def _aget_text_response(
        self,
        user_input: Optional[str] = None,
        system_prompt: Optional[str] = None,
        communication_history: Optional[List[Dict[str, str]]] = None,
    ) -> OmniModelOutput:
        text_response = await self.modkit.text_model.arun(
            system_prompt=system_prompt,
            user_input=user_input,
            communication_history=communication_history,
        )
        return OmniModelOutput(text_response=text_response.text)

    def _get_image_response(
        self,
        user_input: Optional[str] = None,
        system_prompt: Optional[str] = None,
        communication_history: Optional[List[Dict[str, str]]] = None,
    ) -> OmniModelOutput:
        image_description_response = self.modkit.text_model.run(
            system_prompt=system_prompt,
            user_input=user_input,
            communication_history=communication_history,
        )
        image_response = self.modkit.image_generation_model.run(
            system_prompt=system_prompt,
            user_input=image_description_response.text,
            communication_history=communication_history,
        )
        return OmniModelOutput(image_url_response=image_response.image_url)

    async def _aget_image_response(
        self,
        user_input: Optional[str] = None,
        system_prompt: Optional[str] = None,
        communication_history: Optional[List[Dict[str, str]]] = None,
    ) -> OmniModelOutput:
        image_description_response = await self.modkit.text_model.arun(
            system_prompt=system_prompt,
            user_input=user_input,
            communication_history=communication_history,
        )
        image_response = await self.modkit.image_generation_model.arun(
            system_prompt=system_prompt,
            user_input=image_description_response.text,
            communication_history=communication_history,
        )
        return OmniModelOutput(image_url_response=image_response.image_url)

    def _get_audio_response(
        self,
        user_input: Optional[str] = None,
        system_prompt: Optional[str] = None,
        communication_history: Optional[List[Dict[str, str]]] = None,
    ) -> OmniModelOutput:
        text_response = self.modkit.text_model.run(
            system_prompt=system_prompt,
            user_input=user_input,
            communication_history=communication_history,
        )
        audio_response = self.modkit.audio_generation_model.run(
            system_prompt=system_prompt,
            user_input=text_response.text,
            communication_history=communication_history,
        )
        return OmniModelOutput(audio_bytes_response=audio_response.audio_bytes)

    async def _aget_audio_response(
        self,
        user_input: Optional[str] = None,
        system_prompt: Optional[str] = None,
        communication_history: Optional[List[Dict[str, str]]] = None,
    ) -> OmniModelOutput:
        text_response = await self.modkit.text_model.arun(
            system_prompt=system_prompt,
            user_input=user_input,
            communication_history=communication_history,
        )
        audio_response = await self.modkit.audio_generation_model.arun(
            system_prompt=system_prompt,
            user_input=text_response.text,
            communication_history=communication_history,
        )
        return OmniModelOutput(audio_bytes_response=audio_response.audio_bytes)

    def _get_text_with_image_response(
        self,
        user_input: Optional[str] = None,
        system_prompt: Optional[str] = None,
        communication_history: Optional[List[Dict[str, str]]] = None,
    ) -> OmniModelOutput:
        text_response = self.modkit.text_model.run(
            system_prompt=system_prompt,
            user_input=user_input,
            communication_history=communication_history,
        )
        image_description_response = self.modkit.text_model.run(
            system_prompt=system_prompt,
            user_input=user_input,
            communication_history=communication_history,
        )
        image_response = self.modkit.image_generation_model.run(
            system_prompt=system_prompt,
            user_input=image_description_response.text,
            communication_history=communication_history,
        )
        return OmniModelOutput(
            text_response=text_response.text,
            image_url_response=image_response.image_url,
        )

    async def _aget_text_with_image_response(
        self,
        user_input: Optional[str] = None,
        system_prompt: Optional[str] = None,
        communication_history: Optional[List[Dict[str, str]]] = None,
    ) -> OmniModelOutput:
        text_response = await self.modkit.text_model.arun(
            system_prompt=system_prompt,
            user_input=user_input,
            communication_history=communication_history,
        )
        image_description_response = await self.modkit.text_model.arun(
            system_prompt=system_prompt,
            user_input=user_input,
            communication_history=communication_history,
        )
        image_response = await self.modkit.image_generation_model.arun(
            system_prompt=system_prompt,
            user_input=image_description_response.text,
            communication_history=communication_history,
        )
        return OmniModelOutput(
            text_response=text_response.text,
            image_url_response=image_response.image_url,
        )

    def _get_user_input(
        self,
        user_input: Optional[str] = None,
        in_memory_image_stream: Optional[io.BytesIO] = None,
        in_memory_audio_stream: Optional[io.BytesIO] = None,
    ) -> str:
        image_description = None
        if in_memory_image_stream is not None:
            image_description_object = self.modkit.vision_model.run(
                in_memory_image_stream=in_memory_image_stream,
            )
            image_description = str(image_description_object)

            user_input = (
                f"{user_input} {image_description}" if user_input else image_description
            )

        audio_description = None
        if in_memory_audio_stream is not None:
            audio_description_object = self.modkit.audio_recognition_model.run(
                in_memory_audio_stream=in_memory_audio_stream,
            )
            audio_description = str(audio_description_object)

            user_input = (
                f"{user_input} {audio_description}" if user_input else audio_description
            )
        return user_input

    async def _aget_user_input(
        self,
        user_input: Optional[str] = None,
        in_memory_image_stream: Optional[io.BytesIO] = None,
        in_memory_audio_stream: Optional[io.BytesIO] = None,
    ) -> str:
        image_description = None
        if in_memory_image_stream is not None:
            image_description_object = await self.modkit.vision_model.arun(
                in_memory_image_stream=in_memory_image_stream,
            )
            image_description = str(image_description_object)

            user_input = (
                f"{user_input} {image_description}" if user_input else image_description
            )

        audio_description = None
        if in_memory_audio_stream is not None:
            audio_description_object = await self.modkit.audio_recognition_model.arun(
                in_memory_audio_stream=in_memory_audio_stream,
            )
            audio_description = str(audio_description_object)

            user_input = (
                f"{user_input} {audio_description}" if user_input else audio_description
            )
        return user_input

    def run(
        self,
        user_input: Optional[str] = None,
        system_prompt: Optional[str] = None,
        communication_history: Optional[List[Dict[str, str]]] = None,
        in_memory_image_stream: Optional[io.BytesIO] = None,
        in_memory_audio_stream: Optional[io.BytesIO] = None,
    ) -> OmniModelOutput:
        """
        Run the OmniModel with the provided inputs and return the output.
        """
        user_input = self._get_user_input(
            user_input=user_input,
            in_memory_image_stream=in_memory_image_stream,
            in_memory_audio_stream=in_memory_audio_stream,
        )

        # Determine the output type based on the input data
        output_type_model = self.modkit.text_model.run(
            system_prompt=system_prompt,
            pydantic_model=OmniModelOutputType,
            user_input=user_input,
            communication_history=communication_history,
        )
        output_type = output_type_model.output_type

        # Process the input data based on the output type
        if output_type == "image":
            return self._get_image_response(
                user_input=user_input,
                system_prompt=system_prompt,
                communication_history=communication_history,
            )
        elif output_type == "audio":
            return self._get_audio_response(
                user_input=user_input,
                system_prompt=system_prompt,
                communication_history=communication_history,
            )
        elif output_type == "text_with_image":
            return self._get_text_with_image_response(
                user_input=user_input,
                system_prompt=system_prompt,
                communication_history=communication_history,
            )
        else:
            # Use text response as default
            return self._get_text_response(
                user_input=user_input,
                system_prompt=system_prompt,
                communication_history=communication_history,
            )

    async def arun(
        self,
        user_input: Optional[str] = None,
        system_prompt: Optional[str] = None,
        communication_history: Optional[List[Dict[str, str]]] = None,
        in_memory_image_stream: Optional[io.BytesIO] = None,
        in_memory_audio_stream: Optional[io.BytesIO] = None,
    ) -> OmniModelOutput:
        """
        Asynchronously run the OmniModel with the provided inputs and return the output.
        """
        user_input = await self._aget_user_input(
            user_input=user_input,
            in_memory_image_stream=in_memory_image_stream,
            in_memory_audio_stream=in_memory_audio_stream,
        )

        # Determine the output type based on the input data
        output_type_model = await self.modkit.text_model.arun(
            system_prompt=system_prompt,
            pydantic_model=OmniModelOutputType,
            user_input=user_input,
            communication_history=communication_history,
        )
        output_type = output_type_model.output_type

        # Process the input data based on the output type
        if output_type == "image":
            return await self._aget_image_response(
                user_input=user_input,
                system_prompt=system_prompt,
                communication_history=communication_history,
            )
        elif output_type == "audio":
            return await self._aget_audio_response(
                user_input=user_input,
                system_prompt=system_prompt,
                communication_history=communication_history,
            )
        elif output_type == "text_with_image":
            return await self._aget_text_with_image_response(
                user_input=user_input,
                system_prompt=system_prompt,
                communication_history=communication_history,
            )
        else:
            # Use text response as default
            return await self._aget_text_response(
                user_input=user_input,
                system_prompt=system_prompt,
                communication_history=communication_history,
            )
